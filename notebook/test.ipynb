{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promise { <pending> }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image resized\n"
     ]
    }
   ],
   "source": [
    "import { Bitmap, Jimp } from '@jimp/core';\n",
    "const jimp = require(\"jimp\") as typeof import('jimp');\n",
    "\n",
    "var imageData : Bitmap;\n",
    "\n",
    "//resize image to 640x640\n",
    "jimp.read('./sample-images/car-with-licenseplate.jpeg').then((image) => {\n",
    "  imageData = image.resize(640, 640).bitmap;\n",
    "  image.resize(640,640).write('./sample-images/car-with-licenseplate-resized-tiny.jpeg');\n",
    "  console.log(\"Image resized\");\n",
    "}).catch(err => {\n",
    "  console.error(err);\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function defined\n"
     ]
    }
   ],
   "source": [
    "//import { Tensor, InferenceSession } from \"onnxruntime-web\";\n",
    "// import ort from \"onnxruntime-web\";\n",
    "const ort = require('onnxruntime-node') as typeof import('onnxruntime-node'); // onnyruntime-web\n",
    "const { Tensor } = ort as typeof import('onnxruntime-node');\n",
    "\n",
    "interface ImageMetadata {\n",
    "    batch: number;\n",
    "    channels: number;\n",
    "    width: number;\n",
    "    height: number;\n",
    "}\n",
    "\n",
    "function imageDataToTensor(data, imageMetaData:ImageMetadata): any {\n",
    "    // 1a. Extract the R, G, and B channels from the data to form a 3D int array\n",
    "    const [R, G, B] = new Array([], [], []);\n",
    "    for (let i = 0; i < data.length; i += 4) {\n",
    "      R.push(data[i]);\n",
    "      G.push(data[i + 1]);\n",
    "      B.push(data[i + 2]);\n",
    "      // 2. skip data[i + 3] thus filtering out the alpha channel\n",
    "    }\n",
    "    console.log('channels extracted');\n",
    "    ///console.log(R);\n",
    "    //console.log(G);\n",
    "    //console.log(B);\n",
    "    // 1b. concatenate RGB ~= transpose [224, 224, 3] -> [3, 224, 224]\n",
    "    const transposedData = R.concat(G).concat(B);\n",
    "    console.log('data transpose complete');\n",
    "\n",
    "    // 3. convert to float32\n",
    "    let i, l = transposedData.length; // length, we need this for the loop\n",
    "    const float32Data = new Float32Array(imageMetaData.batch * imageMetaData.channels * imageMetaData.width * imageMetaData.height); // create the Float32Array for output\n",
    "    for (i = 0; i < l; i++) {\n",
    "      float32Data[i] = transposedData[i] / 255.0; // convert to float (pixel value range maybe? 255)\n",
    "    }\n",
    "    console.log('data converted to float32');\n",
    "  \n",
    "    const inputTensor = new Tensor(\"float32\", float32Data, [imageMetaData.batch, imageMetaData.channels, imageMetaData.width, imageMetaData.height]);\n",
    "    console.log('inputTensor created');\n",
    "    // inputTensor.data.set(float32Data);\n",
    "    console.log('inputTensor data set');\n",
    "    return inputTensor;\n",
    "  }\n",
    "\n",
    "console.log('function defined');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "const { InferenceSession } = ort as typeof import('onnxruntime-node');\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async function runModel(session, preprocessedData): Promise<[any, number]> {\n",
    "    const start = new Date();\n",
    "    try {\n",
    "    \n",
    "     \n",
    "      const feeds: Record<string,any> = {};\n",
    "      feeds[session.create().inputNames[0]] = preprocessedData;\n",
    "      const outputData = await session.run(feeds);\n",
    "      const end = new Date();\n",
    "      const inferenceTime = (end.getTime() - start.getTime());\n",
    "      const output = outputData[session.outputNames[0]];\n",
    "      return [output, inferenceTime];\n",
    "      \n",
    "    } catch (e) {\n",
    "      console.error(e);\n",
    "      throw new Error();\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imageMetadata {\"width\":640,\"height\":640,\"channels\":3,\"batch\":1}\n",
      "channels extracted\n",
      "data transpose complete\n",
      "data converted to float32\n",
      "inputTensor created\n",
      "inputTensor data set\n",
      "tensor created\n",
      "u8 created\n",
      "session created\n",
      "output h {\n",
      "  dims: [ 1, 5, 8400 ],\n",
      "  type: 'float32',\n",
      "  data: Float32Array(42000) [\n",
      "    11.964459419250488,  11.40317153930664, 11.772724151611328,\n",
      "    20.090736389160156,  41.95893096923828,  59.14415740966797,\n",
      "     53.87537384033203, 48.173118591308594, 45.515830993652344,\n",
      "      45.3691520690918, 57.343292236328125,  68.81871032714844,\n",
      "    115.52296447753906, 115.28607177734375, 124.54100036621094,\n",
      "    126.21919250488281,  127.9874267578125, 137.27052307128906,\n",
      "    142.67034912109375, 146.69973754882812,  149.1882781982422,\n",
      "    159.96739196777344, 181.38278198242188,  196.6282958984375,\n",
      "    198.09735107421875,  198.4817352294922, 201.08047485351562,\n",
      "    201.35208129882812,  202.1505584716797, 207.64581298828125,\n",
      "    214.54132080078125,   221.981201171875,   229.652099609375,\n",
      "    249.72137451171875,  268.7005615234375, 285.62835693359375,\n",
      "    303.46270751953125,  309.4573974609375, 311.39117431640625,\n",
      "         316.240234375,  322.0050964355469,  326.8215637207031,\n",
      "     332.0521240234375,  337.8825378417969,   344.336181640625,\n",
      "     351.5077209472656, 357.69134521484375,  363.0428466796875,\n",
      "    371.07366943359375,     378.9775390625,   381.798095703125,\n",
      "    383.35467529296875,  396.1690673828125, 423.79925537109375,\n",
      "     437.3807373046875, 443.06976318359375,   449.810302734375,\n",
      "     479.2692565917969,  489.3097229003906, 493.24664306640625,\n",
      "     496.9173889160156,  500.1086730957031, 505.98565673828125,\n",
      "          513.23046875,    516.99658203125,  526.1734619140625,\n",
      "     534.4964599609375,  531.8978271484375,  525.0767211914062,\n",
      "     528.4004516601562,      570.654296875,     591.7607421875,\n",
      "        592.0673828125,  598.6079711914062,  601.1588134765625,\n",
      "       602.10986328125,   601.500244140625,  601.3739013671875,\n",
      "           601.9921875,  601.0562133789062, 13.360115051269531,\n",
      "    13.406221389770508, 15.039711952209473,   21.0252742767334,\n",
      "     51.65302276611328,  58.07752227783203, 55.898765563964844,\n",
      "    49.043785095214844, 56.195186614990234, 62.065364837646484,\n",
      "     77.35209655761719,  65.64307403564453,            91.8125,\n",
      "    106.98866271972656, 105.07731628417969,  109.8752212524414,\n",
      "    120.65238952636719, 131.77374267578125, 142.41224670410156,\n",
      "    149.78524780273438,\n",
      "    ... 41900 more items\n",
      "  ],\n",
      "  size: 42000\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import fs  from 'fs';\n",
    "import { Bitmap, Jimp } from '@jimp/core';\n",
    "import { InferenceSession } from 'onnxruntime-web';\n",
    "if (typeof imageData === 'undefined' || imageData === null || typeof imageData.data === 'undefined') {\n",
    "    throw new Error('imageData is undefined');\n",
    "}\n",
    "\n",
    "const imageMetadata = {\n",
    "    width: (imageData as Bitmap).width,\n",
    "    height: (imageData as Bitmap).height,\n",
    "    channels: 3,\n",
    "    batch: 1\n",
    "};\n",
    "\n",
    "console.log('imageMetadata', JSON.stringify(imageMetadata));\n",
    "\n",
    "const tensor = imageDataToTensor((imageData as Bitmap).data, imageMetadata);\n",
    "console.log('tensor created');\n",
    "// create an inference session, using WebGL backend. (default is 'wasm') \n",
    "//const session = await ort.InferenceSession.create('./model/squeezenet1_1.onnx', { executionProviders: ['wasm'] }); \n",
    "const fileBuffer =  fs.readFileSync('./models/lpr-8n.onnx');\n",
    "//convert to unit8array\n",
    "const u8:Uint8Array = new Uint8Array(fileBuffer);\n",
    "console.log('u8 created');\n",
    "const session = await InferenceSession.create(u8); //webgl\n",
    "console.log('session created');\n",
    "\n",
    "/*\n",
    "let output;\n",
    "runModel(session, tensor).then((results) => {   \n",
    "    output = results;\n",
    "    console.log('output', results);\n",
    "}).catch((err) => {\n",
    "    console.log('err', err);\n",
    "}  );\n",
    "*/\n",
    "\n",
    "//const output = (await runModel(session, tensor))[0];\n",
    "\n",
    "    const feeds: Record<string,any> = {};\n",
    "    feeds[session.inputNames[0]] = tensor;\n",
    "const rawSessionResults = await session.run(feeds);\n",
    "const output = rawSessionResults[session.outputNames[0]];\n",
    "console.log('output', output);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    label: 6315,\n",
      "    probability: 636.5421142578125,\n",
      "    bounding: [\n",
      "      303.9048671722412,\n",
      "      67.89016723632812,\n",
      "      588.6362075805664,\n",
      "      1004.5368194580078\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "//import cv from \"@techstark/opencv-js\";\n",
    "const cv = require(\"@techstark/opencv-js\") as typeof import('@techstark/opencv-js');\n",
    "\n",
    "function processResults(results, xRatio, yRatio){\n",
    "    const boxes = [];\n",
    "    //console.log(\"results.dims:\",results.dims);\n",
    "    // looping through output\n",
    "    for (let idx = 0; idx < results.dims[1]; idx++) {\n",
    "      const data = results.data.slice(idx * results.dims[2], (idx + 1) * results.dims[2]); // get rows\n",
    "      //console.log(\"data:\",data);\n",
    "      const box = data.slice(0, 4);\n",
    "      const scores = data.slice(4); // classes probability scores\n",
    "      const score = Math.max(...scores); // maximum probability scores\n",
    "      const label = scores.indexOf(score); // class id of maximum probability scores\n",
    "  \n",
    "      \n",
    "      const [x, y, w, h] = [\n",
    "        (box[0] - 0.5 * box[2]) * xRatio, // upscale left\n",
    "        (box[1] - 0.5 * box[3]) * yRatio, // upscale top\n",
    "        box[2] * xRatio, // upscale width\n",
    "        box[3] * yRatio, // upscale height\n",
    "      ]; // keep boxes in maxSize range\n",
    "      \n",
    "      /*\n",
    "      const [x, y, w, h] = [\n",
    "        box[0] ,// upscale left\n",
    "        box[1] , // upscale top\n",
    "        box[2] , // upscale width\n",
    "        box[3] , // upscale height\n",
    "      ]; // keep boxes in maxSize range\n",
    "      */\n",
    "  \n",
    "      boxes.push({\n",
    "        label: label,\n",
    "        probability: score,\n",
    "        bounding: [x, y, w, h], // upscale box\n",
    "      }); // update boxes to draw later\n",
    "      return boxes;\n",
    "    }\n",
    "\n",
    "}\n",
    "const xRatio = 50;\n",
    "const yRatio = 50;\n",
    "const boxes = processResults(output, xRatio, yRatio);\n",
    "console.log(boxes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessResult:  [ Mat {}, 1, 1 ]\n"
     ]
    }
   ],
   "source": [
    "const { Canvas, createCanvas, Image, ImageData, loadImage } = require('canvas') as typeof import('canvas');\n",
    "const { JSDOM } = require('jsdom') as typeof import('jsdom');\n",
    "\n",
    "\n",
    "/**\n",
    " * Preprocessing image\n",
    " * @param {HTMLImageElement} source image source\n",
    " * @param {Number} modelWidth model input width\n",
    " * @param {Number} modelHeight model input height\n",
    " * @return preprocessed image and configs\n",
    " */\n",
    "const preprocessing = (source, modelWidth, modelHeight) => {\n",
    "    const mat = cv.imread(source); // read from img tag\n",
    "    //const mat = cv.asImageData\n",
    "    const matC3 = new cv.Mat(mat.rows, mat.cols, cv.CV_8UC3); // new image matrix\n",
    "    cv.cvtColor(mat, matC3, cv.COLOR_RGBA2BGR); // RGBA to BGR\n",
    "  \n",
    "    // padding image to [n x n] dim\n",
    "    const maxSize = Math.max(matC3.rows, matC3.cols); // get max size from width and height\n",
    "    const xPad = maxSize - matC3.cols, // set xPadding\n",
    "      xRatio = maxSize / matC3.cols; // set xRatio\n",
    "    const yPad = maxSize - matC3.rows, // set yPadding\n",
    "      yRatio = maxSize / matC3.rows; // set yRatio\n",
    "    const matPad = new cv.Mat(); // new mat for padded image\n",
    "    cv.copyMakeBorder(matC3, matPad, 0, yPad, 0, xPad, cv.BORDER_CONSTANT); // padding black\n",
    "  \n",
    "    const input = cv.blobFromImage(\n",
    "      matPad,\n",
    "      1 / 255.0, // normalize\n",
    "      new cv.Size(modelWidth, modelHeight), // resize to model input size\n",
    "      new cv.Scalar(0, 0, 0),\n",
    "      true, // swapRB\n",
    "      false // crop\n",
    "    ); // preprocessing image matrix\n",
    "  \n",
    "    // release mat opencv\n",
    "    mat.delete();\n",
    "    matC3.delete();\n",
    "    matPad.delete();\n",
    "  \n",
    "    return [input, xRatio, yRatio];\n",
    "  };\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "// Using jsdom and node-canvas we define some global variables to emulate HTML DOM.\n",
    "// Although a complete emulation can be archived, here we only define those globals used\n",
    "// by cv.imread() and cv.imshow().\n",
    "function installDOM() {\n",
    "  const dom = new JSDOM();\n",
    "  global.document = dom.window.document;\n",
    "  // The rest enables DOM image and canvas and is provided by node-canvas\n",
    "  global.Image = Image;\n",
    "  global.HTMLCanvasElement = Canvas;\n",
    "  global.ImageData = ImageData;\n",
    "  global.HTMLImageElement = Image;\n",
    " }\n",
    "\n",
    "\n",
    " try {\n",
    "  installDOM();\n",
    "  const image = await loadImage('./sample-images/car-with-licenseplate-resized.jpeg')\n",
    "  const preprocessResult = preprocessing(image, 640, 640);\n",
    "  console.log(\"preprocessResult: \", preprocessResult);\n",
    "} catch (error) {\n",
    "  console.log(\"error: \", error);\n",
    "}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92:18 - Expected 2-3 arguments, but got 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UncaughtException: Error: Unexpected pending rebuildTimer\n",
      "    at sys.setTimeout (/Users/patrick/.nvm/versions/node/v18.15.0/lib/node_modules/tslab/dist/converter.js:111:19)\n",
      "    at Object.scheduleInvalidateResolutionsOfFailedLookupLocations (/Users/patrick/.nvm/versions/node/v18.15.0/lib/node_modules/tslab/node_modules/@tslab/typescript-for-tslab/lib/typescript.js:122719:55)\n",
      "    at scheduleInvalidateResolutionOfFailedLookupLocation (/Users/patrick/.nvm/versions/node/v18.15.0/lib/node_modules/tslab/node_modules/@tslab/typescript-for-tslab/lib/typescript.js:121553:22)\n",
      "    at /Users/patrick/.nvm/versions/node/v18.15.0/lib/node_modules/tslab/node_modules/@tslab/typescript-for-tslab/lib/typescript.js:121617:11\n",
      "    at /Users/patrick/.nvm/versions/node/v18.15.0/lib/node_modules/tslab/node_modules/@tslab/typescript-for-tslab/lib/typescript.js:5810:11\n",
      "    at /Users/patrick/.nvm/versions/node/v18.15.0/lib/node_modules/tslab/node_modules/@tslab/typescript-for-tslab/lib/typescript.js:5560:101\n",
      "    at Array.forEach (<anonymous>)\n",
      "    at /Users/patrick/.nvm/versions/node/v18.15.0/lib/node_modules/tslab/node_modules/@tslab/typescript-for-tslab/lib/typescript.js:5560:85\n",
      "    at FSWatcher.callbackChangingToMissingFileSystemEntry (/Users/patrick/.nvm/versions/node/v18.15.0/lib/node_modules/tslab/node_modules/@tslab/typescript-for-tslab/lib/typescript.js:6104:11)\n",
      "    at FSWatcher.emit (node:events:513:28)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "const labels = [\"license plate\"];\n",
    "\n",
    "function renderBoxes  (canvas, boxes) {\n",
    "    const ctx = canvas.getContext(\"2d\");\n",
    "    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height); // clean canvas\n",
    "  \n",
    "    const colors = new Colors();\n",
    "  \n",
    "    // font configs\n",
    "    const font = `${Math.max(\n",
    "      Math.round(Math.max(ctx.canvas.width, ctx.canvas.height) / 40),\n",
    "      14\n",
    "    )}px Arial`;\n",
    "    ctx.font = font;\n",
    "    ctx.textBaseline = \"top\";\n",
    "  \n",
    "    boxes.forEach((box) => {\n",
    "      const klass = labels[box.label];\n",
    "      const color = colors.get(box.label);\n",
    "      const score = (box.probability * 100).toFixed(1);\n",
    "      const [x1, y1, width, height] = box.bounding;\n",
    "  \n",
    "      // draw box.\n",
    "      ctx.fillStyle = Colors.hexToRgba(color, 0.2);\n",
    "      ctx.fillRect(x1, y1, width, height);\n",
    "      // draw border box\n",
    "      ctx.strokeStyle = color;\n",
    "      ctx.lineWidth = Math.max(Math.min(ctx.canvas.width, ctx.canvas.height) / 200, 2.5);\n",
    "      ctx.strokeRect(x1, y1, width, height);\n",
    "  \n",
    "      // draw the label background.\n",
    "      ctx.fillStyle = color;\n",
    "      const textWidth = ctx.measureText(klass + \" - \" + score + \"%\").width;\n",
    "      const textHeight = parseInt(font, 10); // base 10\n",
    "      const yText = y1 - (textHeight + ctx.lineWidth);\n",
    "      ctx.fillRect(\n",
    "        x1 - 1,\n",
    "        yText < 0 ? 0 : yText,\n",
    "        textWidth + ctx.lineWidth,\n",
    "        textHeight + ctx.lineWidth\n",
    "      );\n",
    "  \n",
    "      // Draw labels\n",
    "      ctx.fillStyle = \"#ffffff\";\n",
    "      ctx.fillText(klass + \" - \" + score + \"%\", x1 - 1, yText < 0 ? 1 : yText + 1);\n",
    "    });\n",
    "  };\n",
    "  \n",
    "  class Colors {\n",
    "    public readonly palette: string[];\n",
    "    public readonly n: number;\n",
    "    // ultralytics color palette https://ultralytics.com/\n",
    "    constructor() {\n",
    "      this.palette = [\n",
    "        \"#FF3838\",\n",
    "        \"#FF9D97\",\n",
    "        \"#FF701F\",\n",
    "        \"#FFB21D\",\n",
    "        \"#CFD231\",\n",
    "        \"#48F90A\",\n",
    "        \"#92CC17\",\n",
    "        \"#3DDB86\",\n",
    "        \"#1A9334\",\n",
    "        \"#00D4BB\",\n",
    "        \"#2C99A8\",\n",
    "        \"#00C2FF\",\n",
    "        \"#344593\",\n",
    "        \"#6473FF\",\n",
    "        \"#0018EC\",\n",
    "        \"#8438FF\",\n",
    "        \"#520085\",\n",
    "        \"#CB38FF\",\n",
    "        \"#FF95C8\",\n",
    "        \"#FF37C7\",\n",
    "      ];\n",
    "      this.n = this.palette.length;\n",
    "    }\n",
    "  \n",
    "    get = (i) => this.palette[Math.floor(i) % this.n];\n",
    "  \n",
    "    static hexToRgba = (hex, alpha) => {\n",
    "      var result = /^#?([a-f\\d]{2})([a-f\\d]{2})([a-f\\d]{2})$/i.exec(hex);\n",
    "      return result\n",
    "        ? `rgba(${[parseInt(result[1], 16), parseInt(result[2], 16), parseInt(result[3], 16)].join(\n",
    "            \", \"\n",
    "          )}, ${alpha})`\n",
    "        : null;\n",
    "    };\n",
    "  }\n",
    "\n",
    "try {\n",
    "  const canvas = createCanvas();\n",
    "  renderBoxes(canvas, boxes);\n",
    "  fs.writeFileSync('./sample-images/output.jpg', canvas.toBuffer('image/jpeg'));\n",
    "  console.log('done');\n",
    "}catch(err) {\n",
    "  console.log(err);\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  },
  "orig_nbformat": 4,
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
